# Cleaning Data 
Data cleaning, also known as data cleansing or scrubbing, is the process of identifying and correcting (or removing) errors, inconsistencies, and inaccuracies in a dataset. Clean data is crucial for ensuring accurate analysis, reliable machine learning models, and sound decision-making. This process involves dealing with missing values, duplicates, outliers, and other anomalies that can distort analysis.

The project includes 
Loading the dataset after importing the libraries 
Next is exploring the atructures and statistics with handeling the missing values 
After exploring plotting it in the map as well for better understanding of the size and the location in terms of square feet
Next is the correlation analysis which is used to examine the correlations bwtween numerical variables to identify relationaships that can be useful for further analysis
Lastly is the modwl development and deployment

The dataset used in this project:
https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data



